{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caesarcc/pucminas-tcc-fake-news-detection/blob/main/passo02_preparacao_do_PTT5_sumarizador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRD3HmqT1EKZ"
      },
      "source": [
        "## Preparação do Modelo T5, pré-treinado em PT-BR, para sumarização\n",
        "\n",
        "### Iniciando pela configuração do Google Colab, libs externas e acesso ao Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLWPP5tE97EJ",
        "outputId": "ca98cc59-6168-4548-a4ec-02e3ecf292a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 635 kB 14.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 880 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 47.9 MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 233 kB 18.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 75.6 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# lib para utilizar arquitetura transformers\n",
        "!pip install -q transformers==2.9.0\n",
        "# garantir o uso da lib de pytorch testada neste projeto\n",
        "!pip install -q pytorch_lightning==0.7.5\n",
        "# lib necessária para o tokenizador   \n",
        "!pip install -q sentencepiece\n",
        "# lib auxiliar para facilitar o scraping de artigos na web\n",
        "!pip install -q newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EZomSUMMKAf",
        "outputId": "faf566f7-8338-4d2b-b5f9-8c651369d3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Acesso ao Google Driver onde serão salvos os arquivos grandes\n",
        "# Atenção: Todos arquivos usados também estão disponíveis nas pastas modelos e dados, respectivamente\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "CPzAh59THwj1"
      },
      "outputs": [],
      "source": [
        "# Importação de bibliotecas\n",
        "import re\n",
        "import newspaper\n",
        "from transformers import T5Tokenizer\n",
        "from transformers import T5Model, T5ForConditionalGeneration"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga dos modelos pré-treinados em arquitetura transformers, disponíveis na plataforma [Hugging Face](https://huggingface.co/models)"
      ],
      "metadata": {
        "id": "2Oeh72_K2WCf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "XJXnv0l_JFOG",
        "outputId": "b148fe1f-2bd4-4148-e004-7ba0c572de3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4e9087d9bca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unicamp-dl/ptt5-base-portuguese-vocab'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Tokenizador para ptbr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Pesos do modelo em PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_pt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "# Modelo trainado em PT-BR\n",
        "model_name = 'unicamp-dl/ptt5-base-portuguese-vocab'\n",
        "# Tokenizador para ptbr\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "# Pesos do modelo em PyTorch\n",
        "model_pt = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouGMVUwBJFOI",
        "outputId": "d505800b-a31e-4eda-de8c-ec8b4e7df10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Publicidade -\n",
            "\n",
            "Será que a foto mostrando o ex-presidente Lula na capa de maio de 2022 da revista Time é verdadeira ou falsa?\n",
            "\n",
            "A imagem começou a se espalhar nas redes sociais, além de ser bastante c\n"
          ]
        }
      ],
      "source": [
        "artigo = newspaper.Article('https://www.e-farsas.com/a-foto-da-capa-da-revista-time-com-o-ex-presidente-lula-e-real.html', language='pt')\n",
        "artigo.download()\n",
        "artigo.parse()\n",
        "print(artigo.text[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sdLq4bK4JFOK",
        "outputId": "cf26094f-a047-41f7-fcd9-ad5f8bace4be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Será que a foto mostrando o ex-presidente Lula na capa de maio de 2022 da revista Time é verdadeira ou falsa? A imagem começou a se espalhar nas redes sociais, além de ser bastante compartilhada em gr'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Limpar textos\n",
        "def limpar_textos(texto):\n",
        "    texto = str(texto).replace(r'http[\\w:/\\.]+', ' ')  # remover urls\n",
        "    texto = str(texto).replace(r'[^\\.\\w\\s]', ' ')  # remover tudo exceto caracters e pontuação\n",
        "    texto = str(texto).replace('[^a-zA-Z]', ' ')\n",
        "    texto = str(texto).replace(r'\\s\\s+', ' ')\n",
        "    # Remoção de texto entre caracteres de destaque [], () ou --\n",
        "    texto = re.sub(\"[-\\(\\[].*?[\\)\\]-]\", \"\", str(texto))\n",
        "    # Corrige novas linhas indevidas\n",
        "    texto = str(texto).replace(r'\\n', ' ').replace('\\n', ' ')\n",
        "    # Correção das pontuações duplicadas, há muitos casos no dadaset\n",
        "    texto = re.sub(r'(\\W)(?=\\1)', '', str(texto)).replace(\". .\", \".\")\n",
        "    return texto.strip()\n",
        "\n",
        "artigo_limpo = limpar_textos(artigo.text)\n",
        "artigo_limpo[:200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyLD8QdGJFOM",
        "outputId": "221d6c91-e11c-4810-a6ab-c2ed5b59cd60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0, 19066,    13,     7,  3860,  6011,     9,   239,    14,  2670,\n",
            "         10276,    22,  2666,     4,   321,     4,   318,  2570,    11,   752,\n",
            "          4714,    21,  3787,    52,  7931,  1854,    25,  1526,   348,     7,\n",
            "            35,  6322,    33,   117,  2964,  1457,     3,   275,     4,    57,\n",
            "          1125, 18455,    12,   769,    10, 14341,     6,    89,  3006,     8,\n",
            "            10,  3659, 15455,     3,    22,   100,  1082,     4,   321,     4,\n",
            "           318,  2570,     3,     8,  1624,     9,   239,  2013,  4714,     5,\n",
            "           544,   345,    11,  3224,   674,   146,    12,   792,   304,   175,\n",
            "           176,  4780,     4, 10276,    46,     9,  1366,    39,   860,    10,\n",
            "           112,  1445, 10276,  1565, 16930,    16,   150,   157,  8816,     8,\n",
            "          4565,  2618,  5064,     5,   461,   643,    47,    23,     7,   100,\n",
            "           155,    13,  5585,  7931,     6,     4,  2666,     6,    11,  4714,\n",
            "            18,   409,     6,  2633,  8371,    98,    50,  7649,     3,  3536,\n",
            "          6377,   536,    12,  8212,    35,  1296,   155,    67,  1586,    52,\n",
            "            47,     5, 19066,    13,   643,  2666,    21,  1011,  1854, 13340,\n",
            "            52,  4812, 11226,  1854,    25,  2666,    21,  1011,     8,    38,\n",
            "          5025,    23,  1127,    50,  4714,    12,    45,  7551,    19, 20004,\n",
            "            19,   107, 10837,     4,   321,     4,   318,  2570,    46,  1231,\n",
            "           643,  3860,    19, 20004,   403,  2357, 18455,    26, 17426,  6747,\n",
            "           314,    13, 10276,   141,    22,  2666,    11,  4714,  1854,   437,\n",
            "             7,  4714,     3, 10276,    23,  1955,    53,    19,   169,     4,\n",
            "           311,     4,   318,  2570,    12,    99,   196,     8,     9,   239,\n",
            "            14,  2670,  9362,    81,   669,  4255,     3,    29,  1364,    19,\n",
            "           112,     8,   515,    22,  6896,     5,   403,    51, 12023,    39,\n",
            "          7788,     6,     4, 10276,    48,   752,    23, 12564,    37,   409,\n",
            "            11,  6896,     3,  3379,    43,  1273,  3901,    33, 16348,   246,\n",
            "          3826,     5, 10276,   700,    13,     9, 13109,  1220,   150,   304,\n",
            "           192,   332,  1007,    53,    39,   624,     8,    13,   304,  4025,\n",
            "            56,  4053,   141, 11199, 12253,    20,   150,  2390, 20018,     5,\n",
            "            91,  2068,    10,  1625,  5488,     3, 16348,   246,  3826,    21,\n",
            "           304,  1380,  1058,   806,  1849,  2086,   624,   779,   304,  1305,\n",
            "           515,    47,    87,   158,    16, 13877, 20018,     5, 10276,    55,\n",
            "           700,    22,  1955,    13,    94,  1138,     7,  4055,     3,    12,\n",
            "           976,    47,  9446,    82,    13,    35,  7214,  2142,   682,     3,\n",
            "            69,    13, 11547,    13,  2442,  4666,   682,   210,  1340,    34,\n",
            "            39,  6649,     5,     5,     5,   230,  2633,   148,  8902,    22,\n",
            "          2666,    11,  4714, 10276,    47,    23,     9,    90,   364,     7,\n",
            "         17865,    33,     7,  2666,    11,   657,  2743,  1535,    58,   752,\n",
            "           220,    14,  2013,     5,  1757,  1838,     3,     9,   729, 14337,\n",
            "           637,     3,    30,  2092,   639,  8144, 16667,     6,     8,  8696]])\n"
          ]
        }
      ],
      "source": [
        "tokens_entrada = tokenizer.encode(artigo_limpo, return_tensors=\"pt\", max_length=400, truncation=True)\n",
        "\n",
        "# max_length: O número máximo de tokens a serem gerado.\n",
        "# length_penalty: Penalidade exponencial para o comprimento, 1,0 significa sem penalidade.\n",
        "# num_beams: Especifica como usar busca heurística (beam search) em vez de busca gulosa (greedy search), \n",
        "#            O modelo tentará manter as 4 hipóteses mais prováveis ​​em cada passo de tempo.\n",
        "# early_stopping: A geração seja concluída quando todas as hipóteses (beams) atingirem o final do token de string ( EOS ).\n",
        "\n",
        "outputs = model_pt.generate(\n",
        "    tokens_entrada, \n",
        "    max_length=400, \n",
        "    length_penalty=2.0, \n",
        "    num_beams=4, \n",
        "    early_stopping=True)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sdJtLhNJFOO",
        "outputId": "b77809d9-0673-42b7-a1f2-f0958472f34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Será que a foto mostrando o ex-presidente Lula na capa de maio de 2022 da revista Time é verdadeira ou falsa? A imagem começou a se espalhar nas redes sociais, além de ser bastante compartilhada em grupos do WhatsApp e do Telegram, na primeira semana de maio de 2022, e mostra o examericana Time. Ao lado da manchete em inglês “O segundo ato de Lula: o líder mais popular do Brasil”, Lula aparece vestindo um terno escuro e camisa azul clara. Como essa não foi a primeira vez que fotos falsas de capas da Time com presidentes brasileiros circularam pela web, muita gente ficou em dúvida se dessa vez era verdade ou não. Será que essa capa é real? Verdade ou mentira? A capa é real e sua divulgação foi feita pela Time em seu perfil no Instagram no dia 04 de maio de 2022: Ver essa foto no Instagram Uma publicação compartilhada por TIME Por que Lula está na capa da Time? Segundo a Time, Lula foi entrevistado no final de março de 2022 em São Paulo e o ex-presidente falou sobre diversos assuntos, como eleições no Brasil e guerra na Ucrânia. Uma das declarações mais polêmicas de Lula à revista foi referente ao presidente da Ucrânia, Volodymyr Zelensky. Lula disse que o ucraniano poderia ter “negociado mais” e que “ninguém está procurando contribuir para ter paz“. Na visão do petista, Zelensky é “tão responsável quanto Putin” porque “uma guerra não tem apenas um culpado“. Lula também disse na entrevista que quando deixou a presidência, em 2010, não imaginava que se tornaria candidato novamente, mas que percebeu que precisa lutar novamente pelos direitos dos mais pobres... 10 brasileiros já estiveram na capa da Time Lula não foi o primeiro brasileiro a estampar a capa da prestigiada revista norte-americana. Antes dele, o jogador Neymar, os políticos Jânio Quadros e Getúlio\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYVq1HCgX5zB"
      },
      "source": [
        "### Testando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJfQlVjsNqug",
        "outputId": "765e3f8f-e583-4777-c52b-db873979c7e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('drive/MyDrive/PUC/TCC/modelos/t5_sumarizar/tokenizer_config.json',\n",
              " 'drive/MyDrive/PUC/TCC/modelos/t5_sumarizar/special_tokens_map.json',\n",
              " 'drive/MyDrive/PUC/TCC/modelos/t5_sumarizar/spiece.model',\n",
              " 'drive/MyDrive/PUC/TCC/modelos/t5_sumarizar/added_tokens.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CAMINHO_MODELO = \"drive/MyDrive/PUC/TCC/modelos/t5_sumarizar\"\n",
        "model_pt.save_pretrained(f\"{CAMINHO_MODELO}\")\n",
        "tokenizer.save_pretrained(f\"{CAMINHO_MODELO}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "classificacao_passo02_treino_avaliacao.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "50691a0bc379e9e647c9463feff34781ae883c7b810726d51a7ed60c4a02b637"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tcc')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}